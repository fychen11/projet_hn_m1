{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "253f6e47",
      "metadata": {
        "id": "253f6e47"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "\n",
        "#nettoyer le corpus\n",
        "import jieba\n",
        "\n",
        "#modèle LDA\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "#visualiser\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "#calculer les distances\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from scipy.spatial.distance import pdist, squareform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb51136c",
      "metadata": {
        "id": "fb51136c"
      },
      "outputs": [],
      "source": [
        "#étape 1 : préparer les données\n",
        "\n",
        "#importer le fichier excel et extraires les informations de la colonne inscriptions\n",
        "data = pd.read_excel(\"fr_insc.xlsx\")\n",
        "data.fillna(\"\",inplace=True)\n",
        "texte = list(data[\"inscriptions\"])\n",
        "\n",
        "#importer les listes des stopwords\n",
        "jieba.load_userdict(\"dict_txt_big.txt\")\n",
        "with open('stopwords1.txt', encoding = 'UTF-8') as f:\n",
        "    stop_words = f.readlines()\n",
        "\n",
        "#nettoyer les stopwords et supprimant les caractères indésirables\n",
        "stop_words = [w.replace('\\n', '') for w in stop_words]\n",
        "stop_words = [w.replace(' ', '') for w in stop_words]\n",
        "\n",
        "#supprimer les mots vides, les ponctuations, les alphabets, les chiffres et separer\n",
        "rule = re.compile(r\"[^\\u4e00-\\u9fa5\\u3400-\\u4dbf]\") #regex pour ne garder que les caractères chinois\n",
        "texte = [list(jieba.cut(rule.sub('', i))) for i in texte] #couper le texte en liste de phrases\n",
        "for idx, t in enumerate(texte):\n",
        "    texte[idx] = ' '.join([word for word in t if word.strip() not in stop_words]) #supprimer les mots vides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79077c43",
      "metadata": {
        "id": "79077c43"
      },
      "outputs": [],
      "source": [
        "#couper de nouveau la liste de phrases en liste de mots\n",
        "result_fenci = [i.split(' ') for i in texte]\n",
        "v = [sous_liste for sous_liste in result_fenci if all(mot != '' for mot in sous_liste)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a089598",
      "metadata": {
        "id": "3a089598"
      },
      "outputs": [],
      "source": [
        "#étape 2 : stocker les données dans un dictionnaire gensim\n",
        "dictionary = gensim.corpora.Dictionary(v)\n",
        "corpus_final = [dictionary.doc2bow(doc) for doc in v]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee827f53",
      "metadata": {
        "id": "ee827f53"
      },
      "outputs": [],
      "source": [
        "#étape 3 : entrainer le modèle\n",
        "#exécuter le lda, LdaModel pour les données plus petites. Générer 5 topics, passer 100 fois\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus_final,\n",
        "                id2word=dictionary,\n",
        "                num_topics=5,\n",
        "                passes=100,\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff6889b",
      "metadata": {
        "id": "eff6889b"
      },
      "outputs": [],
      "source": [
        "#évaluer\n",
        "#calculer la cohérence\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=v, dictionary=dictionary)\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Cohérence: ', coherence_lda)\n",
        "\n",
        "#calculer la perplexité\n",
        "print('Perplexité: ', lda_model.log_perplexity(corpus_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a51003a7",
      "metadata": {
        "id": "a51003a7"
      },
      "outputs": [],
      "source": [
        "#étape 4 : générer les topics obtenus\n",
        "topics = [] #liste vide pour stocker les thèmes\n",
        "for idx, topic in lda_model.print_topics(-1) : #parcourir tous les mots pour les ajouter à la liste\n",
        "    print(\"Topic: {} -> Words: {}\".format(idx, topic))\n",
        "    topics.append(topic)\n",
        "\n",
        "all_topic_model = [] #liste vide pour stocker les modèles\n",
        "for i in range(len(topics)): #parcourir tous les mots de la liste topics\n",
        "  str = topics[i].split(' + ')\n",
        "  topic_model = [] #liste vide pour enregistrer :\n",
        "  for j in range(10):\n",
        "    weight = str[j][0:5] #les poids\n",
        "    word = str[j][7:len(str[j])-1] #les mots\n",
        "    topic_model.append((weight, word))\n",
        "  all_topic_model.append(topic_model)\n",
        "\n",
        "#stocker le résultat dans un dataframe\n",
        "df_topic_model = pd.DataFrame(all_topic_model)\n",
        "df_topic_model.rename(index = {0: \"Topic 1\", 1: \"Topic 2\", 2: \"Topic 3\", 3: \"Topic 4\", 4: \"Topic 5\", 5: \"Topic 6\", 6: \"Topic 7\", 7: \"Topic 8\", 8: \"Topic 9\", 9: \"Topic 10\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a58833",
      "metadata": {
        "id": "89a58833"
      },
      "outputs": [],
      "source": [
        "#exporter le dataframe\n",
        "df_topic_model.to_excel('lda_t5_tableau.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9916541",
      "metadata": {
        "id": "b9916541"
      },
      "outputs": [],
      "source": [
        "#étape 5 : visualiser\n",
        "pyLDAvis.enable_notebook()\n",
        "vis_data = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary)\n",
        "#exporter au format HTML\n",
        "pyLDAvis.save_html(vis_data, 'lda_t5.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96530a6c",
      "metadata": {
        "id": "96530a6c"
      },
      "outputs": [],
      "source": [
        "#étape 6 : distance et dendrogramme\n",
        "#obtenir la distribution des topics\n",
        "topic_dist = lda_model.state.get_lambda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f13dd528",
      "metadata": {
        "id": "f13dd528"
      },
      "outputs": [],
      "source": [
        "#calculer la distance euclidienne\n",
        "dist = pd.DataFrame(squareform(pdist(topic_dist), 'euclidean'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03a591d",
      "metadata": {
        "id": "d03a591d"
      },
      "outputs": [],
      "source": [
        "#créer un dendrogramme\n",
        "cluster_names = ['T1', 'T2', 'T3', 'T4', 'T5']\n",
        "#cluster_names = ['T1', 'T2', 'T3', 'T4', 'T5','T6', 'T7', 'T8', 'T9', 'T10']\n",
        "dendrogramme = shc.dendrogram(shc.linkage(dist),  labels=cluster_names)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}